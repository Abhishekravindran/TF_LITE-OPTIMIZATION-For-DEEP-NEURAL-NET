{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cnn_Weight_optimization_tf_lite.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhishekravindran/TF_LITE-OPTIMIZATION-For-DEEP-NEURAL-NET/blob/main/Cnn_Weight_optimization_tf_lite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPvVfFccAD-2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s--DxozjCcTd"
      },
      "source": [
        "Lets Try to implement weight Size Allocated in memory by a normal keras dnn by few process as below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzLKpmZICaWN"
      },
      "source": [
        "# importing all the necessary libraries\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import h5py\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sys import getsizeof"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZKNhx8x_1jq"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymcbpqPdLJxW"
      },
      "source": [
        "#Fun to caluclate size\n",
        "def get_file_size(file_path):\n",
        "    size = os.path.getsize(file_path)\n",
        "    return size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vfRLdF_LKUK"
      },
      "source": [
        "#fun to convert a given size into bytes\n",
        "def convert_bytes(size, unit=None):\n",
        "    if unit == \"KB\":\n",
        "        return print('File size: ' + str(round(size / 1024, 3)) + ' Kilobytes')\n",
        "    elif unit == \"MB\":\n",
        "        return print('File size: ' + str(round(size / (1024 * 1024), 3)) + ' Megabytes')\n",
        "    else:\n",
        "        return print('File size: ' + str(size) + ' bytes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24lBAsQm3j6u"
      },
      "source": [
        "# loading the mnist dataset on which we will see the optimization\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
        "x_train.shape,x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzTb7V5F4EAy"
      },
      "source": [
        "#vizualizing\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "i=np.random.randint(0,59999)\n",
        "plt.imshow(x_train[i],cmap='gray')\n",
        "y_train[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRT2_iQj4Dtq"
      },
      "source": [
        "#vizualizing\n",
        "width=12\n",
        "height=12\n",
        "fig,axes=plt.subplots(width,height,figsize=(15,15))\n",
        "axes=axes.ravel() #10*10 =100 converting matrix to vectors\n",
        "for i in np.arange(0,width*height):\n",
        "  index=np.random.randint(0,59999)\n",
        "  axes[i].imshow(x_train[index],cmap='gray');\n",
        "  axes[i].axis('off')\n",
        "  axes[i].set_title(y_train[index],fontsize=10)\n",
        "plt.subplots_adjust(hspace=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAhm7rgx5BS4"
      },
      "source": [
        "#preprocessing\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrVgkVryECo_"
      },
      "source": [
        "Building the model and compiling and doing a fit over the train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x431rruX5BQF"
      },
      "source": [
        "\n",
        "model = keras.Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EAtKNH85BM-"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss= SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAmryAvx5BJr"
      },
      "source": [
        "model.fit(x_train,y_train,epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGOvIBLy5BGM"
      },
      "source": [
        "KERAS_MODEL_NAME = \"tf_digit_mnist.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dehU2YOH5qXj"
      },
      "source": [
        "# saving the model\n",
        "model.save(KERAS_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX2TPc4M5qTa"
      },
      "source": [
        "#now as we can see the size of he file please do keep a note on how we will optimize this without affecting the accuracy\n",
        "convert_bytes(get_file_size(KERAS_MODEL_NAME), \"MB\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARhU_NI15qQY"
      },
      "source": [
        "#keep the note of accuracy for further cross check\n",
        "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbR3ighQA4sZ"
      },
      "source": [
        "Creating a Tf_lite MOdel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNZ9Pfc_6EvQ"
      },
      "source": [
        "TF_LITE_MODEL_FILE_NAME = \"tf_lite_model.tflite\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9cXUQZq6Eq4"
      },
      "source": [
        "# if we have a specific optimization size we can manually give it else directly convert it to min optimium size using the optimizations\n",
        "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tf_lite_converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "# tf_lite_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# tf_lite_converter.target_spec.supported_types = [tf.float16]\n",
        "tflite_model = tf_lite_converter.convert()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwCCnlQM6EoD"
      },
      "source": [
        "tflite_model_name = TF_LITE_MODEL_FILE_NAME\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYFiMLuy6Ek_"
      },
      "source": [
        "#as we can see how we have reduced the storage size from the previous result of keras model \n",
        "convert_bytes(get_file_size(TF_LITE_MODEL_FILE_NAME), \"MB\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVxiQn52AxGj"
      },
      "source": [
        "Checking **Input** Tensor Shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msEl2CMA6EhA"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_path = TF_LITE_MODEL_FILE_NAME)\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1zu6aXmBIbd"
      },
      "source": [
        "Resize the Tensor Shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q4u4rbI6Ed6"
      },
      "source": [
        "interpreter.resize_tensor_input(input_details[0]['index'], (10000, 28, 28))\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], (10000, 10))\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6ijA-0B5qMP"
      },
      "source": [
        "x_test.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP-Hei7Y8akK"
      },
      "source": [
        "x_test_numpy = np.array(x_test, dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1NblfP48agk"
      },
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], x_test_numpy)\n",
        "interpreter.invoke()\n",
        "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
        "prediction_classes = np.argmax(tflite_model_predictions, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shtVsLLi8act"
      },
      "source": [
        "acc = accuracy_score(prediction_classes, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhgtz1mC5qJt"
      },
      "source": [
        "# we can also notice that our model hasnt got tampred with the accuracy much comparitively w.r.t what we had obtained previously\n",
        "print('Test accuracy TFLITE model :', acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL5uxhh_BZ_h"
      },
      "source": [
        "Access Quantized Weights of Keras model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCQtJm-S9Llh"
      },
      "source": [
        "#Lets see how internally we are saving memory so lets randomly take a single intialized weight and check the size occupied\n",
        "print(model.get_weights()[0][0][0], type(model.get_weights()[0][0][0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efP9bbKY9Lh0"
      },
      "source": [
        "keras_weight_var = np.array([model.get_weights()[0][0][0]], dtype=\"float64\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bz34Joo9LfY"
      },
      "source": [
        "print(\"The weight value occupied without optimization is around {} bytes in the memory\".format(getsizeof(keras_weight_var[0]))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ2_av5Z-iI_"
      },
      "source": [
        "In order to access the tflite model weights have to load the model and read the corresponding values form the layers and  save it into an h5 file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfQ52KhK9Lap"
      },
      "source": [
        "TF_LITE_WEIGHTS_TEMP_FILE = \"temp_weights_from_tflite.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDT05fbx9LYA"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=TF_LITE_MODEL_FILE_NAME)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "all_layers_details = interpreter.get_tensor_details() \n",
        "f = h5py.File(TF_LITE_WEIGHTS_TEMP_FILE, \"w\")   \n",
        "for layer in all_layers_details:\n",
        "     grp = f.create_group(str(layer['index']))\n",
        "     grp.attrs[\"name\"] = layer['name']\n",
        "     grp.attrs[\"shape\"] = layer['shape']\n",
        "     grp.attrs[\"quantization\"] = layer['quantization']\n",
        "     grp.create_dataset(\"weights\", data=interpreter.get_tensor(layer['index']))\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2aHAFz2Bl4-"
      },
      "source": [
        "Getting optimized weights of Tflite model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDPT3gWP9LT7"
      },
      "source": [
        "#randomly loading the weight frm our tflite model\n",
        "temp_file = h5py.File(TF_LITE_WEIGHTS_TEMP_FILE, 'r')\n",
        "print(temp_file[\"5\"][\"weights\"][0][6], type(temp_file[\"5\"][\"weights\"][0][6]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxfnCIJ29LRo"
      },
      "source": [
        "quantized_weight_var = np.array([temp_file[\"5\"][\"weights\"][0][6]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy69Jx0j9LO6"
      },
      "source": [
        "print(\"The weight value occupied with optimization is around {} bytes in the memory\".format(getsizeof(quantized_weight_var[0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTsJV7Y4Fcxv"
      },
      "source": [
        "Conclusion as we can see for a single weight there is a difference of 7 bytes imagine a huge deep neural network where in there are 10kk+ neurons then the change/size occupied is enormous and however in scenarios like where we have to implement our dnn model in android mobile phones eg: image detection we cannot afford to provide memory space so high hence we do this optimiztaion for similar working and required accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd3XgXEw5BD6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_vq0uJWGFUs"
      },
      "source": [
        "BElow is the same implementation of optimization on fashion_mnist dataset  and the conclusion remains the same as above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MqDQO0KCaWS"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjnLH5S2CaWx"
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brm0b_KACaWX"
      },
      "source": [
        "## Explore the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW5k_xz1CaWX"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRFYHB2mCaWb"
      },
      "source": [
        "len(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKnCTHz4CaWg"
      },
      "source": [
        "np.unique(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqTxmbVBASQF"
      },
      "source": [
        "# Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KFnYlcwCaWl"
      },
      "source": [
        "test_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJmPr5-ACaWn"
      },
      "source": [
        "len(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES6uQoLKCaWr"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4VEw8Ud9Quh"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[88])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW5WzIPlCaWv"
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## Build & Compile the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ODch-OFCaW4"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhan11blCaW7"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss= SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvwvpA64CaW_"
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n4_BRNKLRwo"
      },
      "source": [
        "KERAS_MODEL_NAME = \"tf_model_fashion_mnist.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_3Y3F4GBWud"
      },
      "source": [
        "model.save(KERAS_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19sd1FJkCHID"
      },
      "source": [
        "convert_bytes(get_file_size(KERAS_MODEL_NAME), \"MB\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_deKtkhCHMu"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BFE9lvwLfgv"
      },
      "source": [
        "# TF Lite Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORAx4Yc7LjwM"
      },
      "source": [
        "TF_LITE_MODEL_FILE_NAME = \"tf_lite_model.tflite\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY57t7EwCW8P"
      },
      "source": [
        "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tf_lite_converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "# tf_lite_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# tf_lite_converter.target_spec.supported_types = [tf.float16]\n",
        "tflite_model = tf_lite_converter.convert()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZxnt1IsCXBb"
      },
      "source": [
        "tflite_model_name = TF_LITE_MODEL_FILE_NAME\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtIdP296CXFl"
      },
      "source": [
        "convert_bytes(get_file_size(TF_LITE_MODEL_FILE_NAME), \"KB\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_gttI3-M45M"
      },
      "source": [
        "# Check Input Tensor Shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJXJuGLFGfjB"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_path = TF_LITE_MODEL_FILE_NAME)\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_X-k46vMzAt"
      },
      "source": [
        "# Resize Tensor Shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6wo8RNFGpXw"
      },
      "source": [
        "interpreter.resize_tensor_input(input_details[0]['index'], (10000, 28, 28))\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], (10000, 10))\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsv7ROq8Gf0f"
      },
      "source": [
        "test_images.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM1alowAHy2d"
      },
      "source": [
        "test_imgs_numpy = np.array(test_images, dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm4bxTIwHErB"
      },
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], test_imgs_numpy)\n",
        "interpreter.invoke()\n",
        "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
        "prediction_classes = np.argmax(tflite_model_predictions, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRKoF30HIZP2"
      },
      "source": [
        "acc = accuracy_score(prediction_classes, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZIF6OenI_5i"
      },
      "source": [
        "print('Test accuracy TFLITE model :', acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw7r5WyUV307"
      },
      "source": [
        "# Get Weights of Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lzqy6REGPxIA"
      },
      "source": [
        "print(model.get_weights()[0][0][0], type(model.get_weights()[0][0][0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drZEEbY5RXJk"
      },
      "source": [
        "keras_weight_var = np.array([model.get_weights()[0][0][0]], dtype=\"float64\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIwkH2EYWKom"
      },
      "source": [
        "getsizeof(keras_weight_var[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuSUIDA_WZ9V"
      },
      "source": [
        "# Access Quantized Weights of TFLite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbzyyvetWhCs"
      },
      "source": [
        "TF_LITE_WEIGHTS_TEMP_FILE = \"temp_weights_from_tflite.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV83qjttPz5E"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=TF_LITE_MODEL_FILE_NAME)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "all_layers_details = interpreter.get_tensor_details() \n",
        "f = h5py.File(TF_LITE_WEIGHTS_TEMP_FILE, \"w\")   \n",
        "for layer in all_layers_details:\n",
        "     grp = f.create_group(str(layer['index']))\n",
        "     grp.attrs[\"name\"] = layer['name']\n",
        "     grp.attrs[\"shape\"] = layer['shape']\n",
        "     grp.attrs[\"quantization\"] = layer['quantization']\n",
        "     grp.create_dataset(\"weights\", data=interpreter.get_tensor(layer['index']))\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTi8OzHmUZF1"
      },
      "source": [
        "temp_file = h5py.File(TF_LITE_WEIGHTS_TEMP_FILE, 'r')\n",
        "print(temp_file[\"5\"][\"weights\"][0][6], type(temp_file[\"5\"][\"weights\"][0][6]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcdUtejoW73F"
      },
      "source": [
        "quantized_weight_var = np.array([temp_file[\"5\"][\"weights\"][0][6]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udfbq6fTXCxa"
      },
      "source": [
        "getsizeof(quantized_weight_var[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUF9xC2iZVsb"
      },
      "source": [
        "temp_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv4y9DS5ZX71"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}